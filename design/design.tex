\documentclass[11pt]{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{epstopdf}
\usepackage{fullpage}


\title{Design Ideas}
\author{Jeffrey Naecker}
\date{\today}
                                
\begin{document}
\maketitle

\section{Optimal Donation Under Risk is Bounded}

Assume that we have an agents whose endowment may be either $e_1$ or $e_2$ with probability $p$ and $1-p$ respectively.  Let $e_1 > e_2$, so state 1 is the ``good" state and state 2 is the ``bad" state.  Then in our design the agent chooses a donation amount $x$ to satisfy
\[
\max_{x \in [0, e_2]} p u(e_1 - x, x) + (1-p) u(e_2 - x, x)
\]
where the utility function $u$ satisfies $u_1>0, u_2>0$ and $u_{11}<0, u_{22}<0$.  That is, more money for either the agent or the other party is better (holding the other amount fixed), but there are decreasing returns.  Additionally, for what follows we will need to assume that $u_{12} < 0$, meaning that as the agent's own income increases, the marginal returns to increasing the other party's income are decreasing.

Note that if we write $D =  [0, e_2]$ and $f(x, p) = p u(e_1 - x, x) + (1-p) u(e_2 - x, x)$ this problem can be rewritten as
\[
\max_{x \in [0, e_2]} f(x, p),
\]
which allows us to apply the Topkis theorem.  The condition for the theorem to be met are as follows.

\begin{enumerate}

\item $D$ is a lattice.  This is trivially true for a line segment.

\item $f$ is supermodular in $x$.  This is trivially true since there is a single choice variable.

\item $f$ has increasing differences in $(x, p)$.  This is satisfied if $\frac{\partial^2 f}{\partial p \partial x} \geq 0$.  Note that 
\[
\frac{\partial f}{\partial p} = u(e_1 - x, x) - u(e_2 - x, x) 
\]
so 
\[
\frac{\partial^2 f}{\partial p \partial x} = -u_1(e_1 - x, x) + u_2(e_1 - x, x) + u_1(e_2 - x, x) - u_2(e_2 - x, x) 
\]
which we can rearrange to get
\[
\frac{\partial^2 f}{\partial p \partial x}   u_1(e_2 - x, x) -u_1(e_1 - x, x) + u_2(e_1 - x, x) - u_2(e_2 - x, x)  .
\]
Note that the first two terms, $u_1(e_2 - x, x) -u_1(e_1 - x, x)$, sum to a positive number by our assumption that $u_{11} < 0$.  The second two terms, $u_2(e_1 - x, x) - u_2(e_2 - x, x)$, will also sum to a positive number by our assumption that $u_{12} < 0$.  Thus $\frac{\partial^2 f}{\partial p \partial x} > 0$ as desired.
\end{enumerate}


Since all the Topkis conditions are satisfied, we can then claim that the optimal choice of $x^*(p)$ is non-decreasing in in $p$.    In particular suppose we let $x^*(1)$ be the optimal donation when $p=1$ (so the endowment is $e_1$ for certain), and $x^*(0)$ be the optimal donation when $p=0$ (so the endowment is $e_2$ for certain).  Then for any case where the endowment is uncertain, ie when $p \in (0,1)$, it must be that $x^*(0) < x^*(p) < x^*(1)$. That is, the optimal donation under risk is somewhere between the optimal donations under the good and bad states.
	
\section{What the Normalization Task Gives Us}

Our normalization task gives us a sequence of numbers $X(N)$ such that the agent is indifferent between \$$N $ for charity 2 and \$$X(N)$ for themselves, ie
\[
(0, 0, N) \sim (X(N), 0, 0).
\]
In our design we currently elicit $X(N)$ for $N \in (5, 6, 7, 8, 9, 10)$.  We can then examine whether $X(N)$ is linear in $N$ or convex.  

However, it is unclear how the normalization task helps us in the remaining tasks.  In rounds 1a, 1b, 2a, 2b, the agent makes maximization decisions that give us the following donation amounts:
\begin{flalign*}
x^*_{1a} &= \arg \max_x u(0, x, 10-x) \\
x^*_{1b} &= \arg \max_x u(X(10) - x, x, 0) \\
x^*_{2a}(q) &= \arg \max_x q u(0, x, 10-x)  + (1-q) u(0, x, 5-x) \\
x^*_{2b}(q) &= \arg \max_x q u(X(10) - x, x, 0) + (1-q) u(X(5) - x, x, 0) 
\end{flalign*}
where the last two lines are collected for a series of $q$ we have not determined yet.  It is not clear how the normalization tasks helps us make any statements about the relationship between the various $x*$.  In fact I am not even sure what our intuitive predictions would be.


















\end{document}  